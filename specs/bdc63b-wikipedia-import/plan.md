---
runId: bdc63b
feature: wikipedia-import
created: 2025-01-20
status: ready
---

# Feature: Wikipedia Event Import - Implementation Plan

> **Generated by:** Task Decomposition skill
> **From spec:** specs/bdc63b-wikipedia-import/spec.md
> **Created:** 2025-01-20

## Execution Summary

- **Total Tasks**: 5
- **Total Phases**: 4
- **Sequential Time**: 25h
- **Parallel Time**: 21h
- **Time Savings**: 4h (16%)

**Parallel Opportunities:**
- Phase 1: 2 tasks (4h saved by running Database Foundation and Wikipedia Parser simultaneously)

**Task Breakdown:**
- M (3-5h): 3 tasks (60%)
- L (5-7h): 2 tasks (40%)
- S (1-2h): 0 tasks (0%)

---

## Phase 1: Foundation

**Strategy**: Parallel
**Reason**: Task 1 (database layer) and Task 2 (parser subsystem) have no shared files and can run independently. This phase saves 4h by executing both tasks simultaneously.

### Task 1.1: Database Foundation

**Complexity**: M (4h)

**Dependencies**: None (foundation task)

**Files**:
- `prisma/schema.prisma`
- `prisma/migrations/`
- `src/lib/models/person-model.ts`
- `src/lib/models/work-model.ts`

**Description**:

Add Wikipedia integration to the database layer by adding `wikipediaSlug` fields to Person and Work models. This enables deduplication during import (same person nominated in multiple categories creates a single Person record).

Update the model layer with methods to find or create entities by Wikipedia slug, supporting the service layer's deduplication logic.

**Implementation Steps**:

1. **Add wikipediaSlug fields to Prisma schema**:
   - Open `prisma/schema.prisma`
   - Add to `Person` model:
     ```prisma
     wikipediaSlug String? @unique  // e.g., "Cillian_Murphy"

     @@index([wikipediaSlug])
     ```
   - Add to `Work` model:
     ```prisma
     wikipediaSlug String? @unique  // e.g., "Oppenheimer_(film)"

     @@index([wikipediaSlug])
     ```
   - Follow schema-rules.md naming conventions (camelCase fields)

2. **Create and run migration**:
   ```bash
   pnpm db:migrate add_wikipedia_slugs
   ```
   - Verify migration file created in `prisma/migrations/`
   - Confirm fields are nullable (supports manually-created records)
   - Confirm unique constraints and indexes applied

3. **Update person-model.ts**:
   - Open `src/lib/models/person-model.ts`
   - Add new function:
     ```typescript
     export async function findOrCreateByWikipediaSlug(data: {
       wikipediaSlug: string;
       name: string;
       imageUrl?: string;
     }) {
       return await prisma.person.upsert({
         where: { wikipediaSlug: data.wikipediaSlug },
         update: {}, // Don't overwrite existing data
         create: data,
       });
     }
     ```
   - Follow architecture.md (models do Prisma queries only, no business logic)

4. **Update work-model.ts**:
   - Open `src/lib/models/work-model.ts`
   - Add new function (same pattern as person-model):
     ```typescript
     export async function findOrCreateByWikipediaSlug(data: {
       wikipediaSlug: string;
       title: string;
       imageUrl?: string;
       year?: number;
     }) {
       return await prisma.work.upsert({
         where: { wikipediaSlug: data.wikipediaSlug },
         update: {}, // Don't overwrite existing data
         create: data,
       });
     }
     ```

5. **Verify with Prisma Studio**:
   ```bash
   pnpm db:studio
   ```
   - Check Person and Work models have wikipediaSlug fields
   - Verify unique constraints appear in Studio

**Acceptance Criteria**:

- [ ] `wikipediaSlug` fields added to Person and Work models in schema.prisma
- [ ] Migration `add_wikipedia_slugs` created and applied successfully
- [ ] Unique constraints and indexes applied to wikipediaSlug fields
- [ ] `findOrCreateByWikipediaSlug` methods added to person-model.ts and work-model.ts
- [ ] Methods follow upsert pattern (create if not exists, return existing if found)
- [ ] Prisma Studio shows wikipediaSlug fields with unique constraints
- [ ] Linting passes: `pnpm lint`

**Mandatory Patterns**:

> **Constitution**: Follow architecture.md (models layer: Prisma queries only, no business logic)

> **Schema Rules**: Follow schema-rules.md (camelCase fields, proper indexing, nullable fields for optional data)

**Quality Gates**:
```bash
pnpm lint
pnpm db:studio  # Visual verification
```

---

### Task 1.2: Wikipedia Parser & Adapter

**Complexity**: L (6h)

**Dependencies**: None (independent parser subsystem)

**Files**:
- `package.json`
- `src/lib/parsers/wikipedia/wikipedia-parser.ts`
- `src/lib/parsers/wikipedia/wikipedia-adapter.ts`
- `src/lib/parsers/wikipedia/types.ts`

**Description**:

Create the Wikipedia parsing subsystem that fetches and parses Wikipedia pages to extract event data. This is a complete, isolated subsystem with no dependencies on the database layer.

The parser fetches raw Wikipedia data via API, the adapter transforms it to Prisma-compatible types, and types define the parser-specific data structures.

**Implementation Steps**:

1. **Install wtf_wikipedia dependency**:
   ```bash
   pnpm add wtf_wikipedia
   ```
   - Verify version compatible with project (check latest stable)
   - See: https://github.com/spencermountain/wtf_wikipedia

2. **Create parser types**:
   - Create `src/lib/parsers/wikipedia/types.ts`:
     ```typescript
     export type ParsedNomination = {
       personName?: string;
       personWikipediaSlug?: string;
       personImageUrl?: string;
       workTitle?: string;
       workWikipediaSlug?: string;
       workImageUrl?: string;
       workYear?: number;
       isWinner?: boolean;
     };

     export type ParsedCategory = {
       name: string;
       pointValue: number;
       nominations: ParsedNomination[];
     };

     export type ParsedEvent = {
       name: string;
       date: Date;
       slug: string;
       description?: string;
       categories: ParsedCategory[];
     };
     ```
   - Follow patterns.md (no type assertions, explicit types)

3. **Implement wikipedia-parser.ts**:
   - Create `src/lib/parsers/wikipedia/wikipedia-parser.ts`
   - **NO Prisma imports** (parser layer must be database-agnostic)
   - Implement `parse(url: string): Promise<ParsedEvent>`:
     - Validate URL is Wikipedia format
     - Extract page title from URL
     - Call Wikipedia API:
       ```
       https://en.wikipedia.org/w/api.php?action=parse&page={title}&format=json&prop=wikitext
       ```
     - Parse wikitext using wtf_wikipedia
     - Extract event metadata (name, date from title or infobox)
     - Extract categories (look for sections/tables with nominations)
     - Extract nominations with Person/Work data
     - Extract Wikipedia slugs from internal links
     - Extract image URLs from Wikimedia Commons
     - Return structured ParsedEvent
   - Handle errors (API timeout, parse failure, missing data)
   - Follow patterns.md (validate inputs with Zod if needed)

4. **Implement wikipedia-adapter.ts**:
   - Create `src/lib/parsers/wikipedia/wikipedia-adapter.ts`
   - **NO external API calls, NO database access** (adapter is pure transformation)
   - Implement `transformToPreview(parsed: ParsedEvent)`:
     - Transform ParsedEvent → preview data structure
     - Normalize strings (trim whitespace)
     - Parse dates to ISO format
     - Extract Wikipedia slugs from URLs (e.g., "https://en.wikipedia.org/wiki/Cillian_Murphy" → "Cillian_Murphy")
     - Return data suitable for preview UI
   - Implement `transformToPrismaInput(parsed: ParsedEvent): Prisma.EventCreateInput`:
     - Transform ParsedEvent → Prisma nested create input
     - Include nested categories and nominations
     - Format for transaction in service layer
   - Follow architecture.md (adapter transforms data, no side effects)

5. **Test parser with real Wikipedia page**:
   - Create test file or use Node REPL:
     ```typescript
     import { parse } from './wikipedia-parser';
     const result = await parse('https://en.wikipedia.org/wiki/97th_Academy_Awards');
     console.log(result);
     ```
   - Verify structure matches ParsedEvent type
   - Verify categories and nominations extracted
   - Verify Wikipedia slugs extracted correctly

**Acceptance Criteria**:

- [ ] `wtf_wikipedia` dependency installed in package.json
- [ ] Parser types defined in types.ts (ParsedEvent, ParsedCategory, ParsedNomination)
- [ ] wikipedia-parser.ts has NO Prisma imports (database-agnostic)
- [ ] `parse(url)` function fetches Wikipedia API and returns ParsedEvent
- [ ] Parser extracts event metadata, categories, nominations, and images
- [ ] wikipedia-adapter.ts has NO external API calls or database access
- [ ] `transformToPreview()` and `transformToPrismaInput()` functions implemented
- [ ] Parser tested with real Wikipedia URL (e.g., 97th Academy Awards)
- [ ] Error handling for invalid URLs, API failures, parse errors
- [ ] Linting passes: `pnpm lint`

**Mandatory Patterns**:

> **Constitution**: Follow architecture.md (parser layer: NO Prisma, NO database access)

> **Layer Boundaries**: Parser must be database-agnostic. Adapter transforms data without side effects.

**Quality Gates**:
```bash
pnpm lint
# Manual test with real Wikipedia URL
node --loader ts-node/esm -e "import('./src/lib/parsers/wikipedia/wikipedia-parser.js').then(m => m.parse('https://en.wikipedia.org/wiki/97th_Academy_Awards').then(console.log))"
```

---

## Phase 2: Business Logic

**Strategy**: Sequential
**Reason**: Task 2.1 depends on Phase 1 completing (uses models from Task 1.1 and parser from Task 1.2).

### Task 2.1: Import Service Layer

**Complexity**: M (5h)

**Dependencies**:
- Task 1.1 (uses person-model and work-model)
- Task 1.2 (uses wikipedia-parser and wikipedia-adapter)

**Files**:
- `src/lib/services/wikipedia-import-service.ts`

**Description**:

Implement the orchestration layer that coordinates parsing, deduplication, and database transactions. This service provides two modes: preview (parse and transform without saving) and commit (save to database atomically).

The service calls the parser to fetch Wikipedia data, uses the adapter to transform it, deduplicates Person/Work entities via model methods, and wraps all creates in a Prisma transaction.

**Implementation Steps**:

1. **Create wikipedia-import-service.ts**:
   - Create `src/lib/services/wikipedia-import-service.ts`
   - Import models from Task 1.1
   - Import parser and adapter from Task 1.2
   - Follow architecture.md (services call models, NOT Prisma directly)

2. **Implement preview mode**:
   ```typescript
   export async function previewImport(url: string) {
     // Call parser
     const parsed = await wikipediaParser.parse(url);

     // Call adapter for preview transformation
     const preview = wikipediaAdapter.transformToPreview(parsed);

     // Return preview data WITHOUT saving to database
     return {
       event: { name: parsed.name, date: parsed.date, slug: parsed.slug },
       categoryCount: parsed.categories.length,
       nominationCount: parsed.categories.reduce((sum, c) => sum + c.nominations.length, 0),
       categories: preview.categories,
     };
   }
   ```
   - No database access in preview mode
   - Return structured data for UI display

3. **Implement commit mode with deduplication**:
   ```typescript
   export async function commitImport(url: string) {
     // Parse and transform
     const parsed = await wikipediaParser.parse(url);
     const prismaInput = wikipediaAdapter.transformToPrismaInput(parsed);

     // Start transaction
     return await prisma.$transaction(async (tx) => {
       // Deduplicate Person entities
       const persons = new Map<string, Person>();
       for (const category of parsed.categories) {
         for (const nomination of category.nominations) {
           if (nomination.personWikipediaSlug && !persons.has(nomination.personWikipediaSlug)) {
             const person = await personModel.findOrCreateByWikipediaSlug({
               wikipediaSlug: nomination.personWikipediaSlug,
               name: nomination.personName!,
               imageUrl: nomination.personImageUrl,
             });
             persons.set(nomination.personWikipediaSlug, person);
           }
         }
       }

       // Deduplicate Work entities (same pattern)
       const works = new Map<string, Work>();
       // ... similar to persons

       // Create Event with nested Categories and Nominations
       const event = await tx.event.create({
         data: {
           ...prismaInput,
           categories: {
             create: parsed.categories.map(cat => ({
               name: cat.name,
               pointValue: cat.pointValue,
               nominations: {
                 create: cat.nominations.map(nom => ({
                   personId: nom.personWikipediaSlug ? persons.get(nom.personWikipediaSlug)?.id : undefined,
                   workId: nom.workWikipediaSlug ? works.get(nom.workWikipediaSlug)?.id : undefined,
                   isWinner: nom.isWinner ?? false,
                 })),
               },
             })),
           },
         },
       });

       return event;
     });
   }
   ```
   - Wrap all creates in transaction (atomic all-or-nothing)
   - Deduplicate Person/Work by wikipediaSlug
   - Use model methods (NOT direct Prisma calls)
   - Transaction rolls back on any error

4. **Add error handling**:
   - Catch parser errors (API timeout, parse failure)
   - Catch validation errors (missing required fields)
   - Catch database errors (duplicate event slug, constraint violations)
   - Throw descriptive errors for action layer to handle

5. **Test service methods**:
   - Test preview mode returns correct structure
   - Test commit mode creates all records
   - Test deduplication (same person in multiple categories)
   - Test transaction rollback on error

**Acceptance Criteria**:

- [ ] `previewImport(url)` function parses Wikipedia page and returns preview data
- [ ] Preview mode does NOT save to database
- [ ] `commitImport(url)` function creates Event, Categories, Nominations, Persons, Works
- [ ] Commit mode wraps all creates in Prisma transaction (atomic)
- [ ] Deduplication logic uses `findOrCreateByWikipediaSlug` from models
- [ ] Same person nominated in multiple categories creates single Person record
- [ ] Service calls models (NOT Prisma directly) per architecture.md
- [ ] Transaction rolls back on any error (no partial imports)
- [ ] Error messages are descriptive (API timeout, parse failure, duplicate slug)
- [ ] Linting passes: `pnpm lint`

**Mandatory Patterns**:

> **Constitution**: Follow architecture.md (services call models, NOT Prisma directly)

> **Transactions**: Use Prisma transactions for atomic operations (all-or-nothing)

> **Error Handling**: Throw descriptive errors with context for action layer

**Quality Gates**:
```bash
pnpm lint
# Manual test (requires database running)
pnpm db:studio  # Verify records created correctly
```

---

## Phase 3: API Layer

**Strategy**: Sequential
**Reason**: Task 3.1 depends on Task 2.1 (uses wikipedia-import-service).

### Task 3.1: Server Actions & Schemas

**Complexity**: M (4h)

**Dependencies**: Task 2.1 (uses wikipedia-import-service)

**Files**:
- `src/schemas/wikipedia-import-schema.ts`
- `src/lib/actions/wikipedia-import-actions.ts`

**Description**:

Create the API surface for Wikipedia import using Server Actions. This includes Zod schemas for validation and next-safe-action wrappers for admin-only access.

Actions validate inputs, call the service layer, and handle redirects/errors for the UI layer.

**Implementation Steps**:

1. **Create Zod validation schemas**:
   - Create `src/schemas/wikipedia-import-schema.ts`:
     ```typescript
     import { z } from 'zod';

     export const wikipediaUrlSchema = z.object({
       url: z
         .string()
         .url()
         .refine(
           (url) => url.includes('wikipedia.org/wiki/'),
           { message: 'Must be a valid Wikipedia URL' }
         ),
     });

     export const previewDataSchema = z.object({
       url: z.string().url(),
       event: z.object({
         name: z.string(),
         date: z.date(),
         slug: z.string(),
       }),
       categoryCount: z.number().int().positive(),
       nominationCount: z.number().int().positive(),
     });

     export type WikipediaUrlInput = z.infer<typeof wikipediaUrlSchema>;
     export type PreviewData = z.infer<typeof previewDataSchema>;
     ```
   - Follow patterns.md (all inputs validated with Zod)

2. **Create previewImportAction**:
   - Create `src/lib/actions/wikipedia-import-actions.ts`
   - Import `adminAction` from safe-action.ts
   - Implement:
     ```typescript
     export const previewImportAction = adminAction
       .schema(wikipediaUrlSchema)
       .action(async ({ parsedInput }) => {
         try {
           const preview = await wikipediaImportService.previewImport(parsedInput.url);
           return { success: true, data: preview };
         } catch (error) {
           if (error instanceof WikipediaParseError) {
             return { success: false, error: 'Failed to parse Wikipedia page' };
           }
           if (error instanceof WikipediaAPIError) {
             return { success: false, error: 'Failed to fetch Wikipedia page' };
           }
           throw error; // Let next-safe-action handle unexpected errors
         }
       });
     ```
   - Use adminAction middleware (admin-only access)
   - Handle known errors, re-throw unexpected ones

3. **Create confirmImportAction**:
   - Implement:
     ```typescript
     export const confirmImportAction = adminAction
       .schema(wikipediaUrlSchema)
       .action(async ({ parsedInput }) => {
         try {
           const event = await wikipediaImportService.commitImport(parsedInput.url);

           // Redirect to event detail page
           redirect(routes.admin.events.detail(event.id));
         } catch (error) {
           if (error instanceof PrismaError && error.code === 'P2002') {
             return { success: false, error: 'Event already imported (duplicate slug)' };
           }
           if (error instanceof WikipediaParseError) {
             return { success: false, error: 'Failed to parse Wikipedia page' };
           }
           throw error;
         }
       });
     ```
   - Call service commit mode
   - Redirect to event detail on success (use routes.ts)
   - Handle duplicate slug error (Prisma P2002)

4. **Test actions with useAction hook**:
   - Create temporary test component:
     ```typescript
     'use client';
     import { useAction } from 'next-safe-action/hooks';
     import { previewImportAction } from '@/lib/actions/wikipedia-import-actions';

     export function TestPreview() {
       const { execute, result } = useAction(previewImportAction);
       // Test preview flow
     }
     ```
   - Verify preview returns data
   - Verify confirm redirects to event detail
   - Verify error handling works

**Acceptance Criteria**:

- [ ] `wikipediaUrlSchema` validates Wikipedia URLs (rejects non-Wikipedia URLs)
- [ ] `previewDataSchema` validates preview data structure
- [ ] `previewImportAction` uses adminAction middleware (admin-only)
- [ ] Preview action validates URL with Zod, calls service, returns preview data
- [ ] `confirmImportAction` uses adminAction middleware (admin-only)
- [ ] Confirm action validates URL, calls service commit, redirects to event detail
- [ ] Redirect uses centralized routes object: `routes.admin.events.detail(event.id)`
- [ ] Error handling for parse failures, API errors, duplicate slugs
- [ ] Error messages are actionable ("Failed to parse Wikipedia page" vs generic errors)
- [ ] Linting passes: `pnpm lint`

**Mandatory Patterns**:

> **Constitution**: Follow patterns.md (all actions use next-safe-action with Zod validation)

> **Centralized Routes**: Use routes.ts for ALL navigation (no hardcoded route strings)

> **Admin Access**: Use adminAction middleware per patterns.md

**Quality Gates**:
```bash
pnpm lint
# Integration test with UI components in Phase 4
```

---

## Phase 4: User Interface

**Strategy**: Sequential
**Reason**: Task 4.1 depends on Task 3.1 (uses wikipedia-import-actions).

### Task 4.1: Import UI

**Complexity**: L (6h)

**Dependencies**: Task 3.1 (uses wikipedia-import-actions)

**Files**:
- `src/app/(admin)/admin/import/page.tsx`
- `src/app/(admin)/admin/import/_components/import-form.tsx`
- `src/app/(admin)/admin/import/_components/preview-table.tsx`
- `src/lib/routes.ts`

**Description**:

Create the complete user-facing Wikipedia import feature. This includes the import wizard page (Server Component), URL input form (Client Component), and preview display (Client Component).

The UI follows Server/Client boundaries per patterns.md: Server Components for layout and data fetching, Client Components for interactivity.

**Implementation Steps**:

1. **Add routes to routes.ts**:
   - Open `src/lib/routes.ts`
   - Add to admin section:
     ```typescript
     admin: {
       // ... existing routes
       import: "/admin/import",
       events: {
         detail: (id: string) => `/admin/events/${id}`,
       },
     }
     ```
   - Follow patterns.md (centralized routes for ALL navigation)

2. **Create import page (Server Component)**:
   - Create `src/app/(admin)/admin/import/page.tsx`:
     ```typescript
     import { ImportForm } from './_components/import-form';

     export default async function ImportPage() {
       return (
         <div className="container mx-auto py-8">
           <h1 className="text-3xl font-bold mb-6">Import Event from Wikipedia</h1>
           <ImportForm />
         </div>
       );
     }
     ```
   - Server Component (async, no onClick handlers)
   - Layout and structure only

3. **Create import form (Client Component)**:
   - Create `src/app/(admin)/admin/import/_components/import-form.tsx`:
     ```typescript
     'use client';

     import { useAction } from 'next-safe-action/hooks';
     import { useState } from 'react';
     import { previewImportAction, confirmImportAction } from '@/lib/actions/wikipedia-import-actions';
     import { PreviewTable } from './preview-table';

     export function ImportForm() {
       const [url, setUrl] = useState('');
       const { execute: preview, result: previewResult, isExecuting: isPreviewing } = useAction(previewImportAction);
       const { execute: confirm, isExecuting: isConfirming } = useAction(confirmImportAction);

       const handlePreview = () => {
         preview({ url });
       };

       const handleConfirm = () => {
         confirm({ url });
       };

       return (
         <div>
           <div className="mb-6">
             <label htmlFor="wikipedia-url" className="block text-sm font-medium mb-2">
               Wikipedia URL
             </label>
             <input
               id="wikipedia-url"
               type="url"
               value={url}
               onChange={(e) => setUrl(e.target.value)}
               placeholder="https://en.wikipedia.org/wiki/97th_Academy_Awards"
               className="w-full px-4 py-2 border rounded"
             />
             <button
               onClick={handlePreview}
               disabled={isPreviewing || !url}
               className="mt-4 px-6 py-2 bg-blue-600 text-white rounded disabled:opacity-50"
             >
               {isPreviewing ? 'Loading...' : 'Preview Import'}
             </button>
           </div>

           {previewResult?.data && (
             <PreviewTable
               preview={previewResult.data}
               onConfirm={handleConfirm}
               isConfirming={isConfirming}
             />
           )}

           {previewResult?.serverError && (
             <div className="p-4 bg-red-50 text-red-700 rounded">
               {previewResult.serverError}
             </div>
           )}
         </div>
       );
     }
     ```
   - Client Component (has onClick, onChange, useState)
   - Uses useAction hook from next-safe-action
   - Shows loading states
   - Displays errors from server

4. **Create preview table (Client Component)**:
   - Create `src/app/(admin)/admin/import/_components/preview-table.tsx`:
     ```typescript
     'use client';

     import type { PreviewData } from '@/schemas/wikipedia-import-schema';

     type PreviewTableProps = {
       preview: PreviewData;
       onConfirm: () => void;
       isConfirming: boolean;
     };

     export function PreviewTable({ preview, onConfirm, isConfirming }: PreviewTableProps) {
       return (
         <div className="border rounded-lg p-6">
           <h2 className="text-2xl font-bold mb-4">Preview: {preview.event.name}</h2>

           <div className="grid grid-cols-3 gap-4 mb-6">
             <div>
               <p className="text-sm text-gray-600">Date</p>
               <p className="text-lg font-semibold">{new Date(preview.event.date).toLocaleDateString()}</p>
             </div>
             <div>
               <p className="text-sm text-gray-600">Categories</p>
               <p className="text-lg font-semibold">{preview.categoryCount}</p>
             </div>
             <div>
               <p className="text-sm text-gray-600">Nominations</p>
               <p className="text-lg font-semibold">{preview.nominationCount}</p>
             </div>
           </div>

           {/* Show sample categories/nominations for validation */}
           <div className="mb-6">
             <h3 className="font-semibold mb-2">Sample Categories</h3>
             {/* Render first few categories with nomination counts */}
           </div>

           <button
             onClick={onConfirm}
             disabled={isConfirming}
             className="px-6 py-2 bg-green-600 text-white rounded disabled:opacity-50"
           >
             {isConfirming ? 'Importing...' : 'Confirm Import'}
           </button>
         </div>
       );
     }
     ```
   - Client Component (has onClick handler)
   - Displays preview data for admin validation
   - Shows loading state during import

5. **Test end-to-end flow**:
   - Start dev server: `pnpm dev`
   - Navigate to `/admin/import`
   - Paste Wikipedia URL (e.g., 97th Academy Awards)
   - Click "Preview Import"
   - Verify preview shows event name, date, category count, nomination count
   - Click "Confirm Import"
   - Verify redirects to event detail page
   - Verify database has Event, Categories, Nominations, Persons, Works
   - Test error cases (invalid URL, duplicate import)

**Acceptance Criteria**:

- [ ] Routes added to routes.ts (`admin.import`, `admin.events.detail`)
- [ ] Import page created at `/admin/import` (Server Component)
- [ ] ImportForm component created (Client Component with form state)
- [ ] PreviewTable component created (Client Component with preview display)
- [ ] Form validates Wikipedia URL format client-side
- [ ] Preview shows event name, date, category count, nomination count
- [ ] Preview shows sample categories/nominations for validation
- [ ] Confirm button triggers import and redirects to event detail
- [ ] Loading states shown during preview and confirm actions
- [ ] Error messages displayed for API failures, parse errors, duplicates
- [ ] Server/Client boundaries respected per patterns.md
- [ ] End-to-end flow works (paste URL → preview → confirm → redirect)
- [ ] Linting passes: `pnpm lint`

**Mandatory Patterns**:

> **Constitution**: Follow patterns.md (Server/Client component boundaries)

> **Server Components**: Can be async, use server actions in form action prop, NO onClick/onChange

> **Client Components**: Can use event handlers and hooks, CANNOT be async functions

> **Centralized Routes**: Use routes.ts for ALL navigation (no hardcoded strings)

**Quality Gates**:
```bash
pnpm lint
pnpm dev  # Manual end-to-end testing
```

---

## Final Verification

After all phases complete, verify the entire feature:

```bash
# Linting
pnpm lint

# Database verification
pnpm db:studio

# End-to-end test
pnpm dev
# Navigate to /admin/import
# Import real Wikipedia page (e.g., 97th Academy Awards)
# Verify all data created correctly
```

**Constitution Compliance Checklist**:

- [ ] All patterns followed (patterns.md):
  - Server actions use next-safe-action with Zod validation
  - All routes use centralized routes object
  - Server/Client component boundaries respected
  - No type assertions without validation
  - ts-pattern used for discriminated unions (if any)

- [ ] Architecture boundaries respected (architecture.md):
  - Parser has no Prisma imports
  - Service calls models (not Prisma directly)
  - Actions call services (not models directly)
  - UI calls actions (not services directly)

- [ ] Schema rules followed (schema-rules.md):
  - Proper indexing on wikipediaSlug
  - Naming conventions (camelCase fields, PascalCase models)
  - Nullable fields for optional data

**Success Criteria**:

- Admin can paste Wikipedia URL and see preview
- Preview shows event name, date, category count, nomination count
- Admin can confirm preview to create event atomically
- Same person nominated in multiple categories creates single Person record
- Import fails atomically if parsing fails (no partial data)
- Successful import redirects to Event detail page
- Error messages are actionable and user-friendly

---

## Execution Strategy

**Recommended approach:**

1. **Phase 1 (Parallel)**: Use git worktrees or separate terminals to run Task 1.1 and Task 1.2 simultaneously
   - Terminal 1: Database Foundation
   - Terminal 2: Wikipedia Parser & Adapter
   - This saves 4h of execution time

2. **Phases 2-4 (Sequential)**: Execute tasks in order after Phase 1 completes
   - Each task builds on previous tasks
   - Run quality gates between tasks

**Alternative (linear execution):**
Execute tasks in order 1.1 → 1.2 → 2.1 → 3.1 → 4.1 if you prefer sequential workflow.

---

**Plan Status**: Ready for execution
**Next Step**: `/execute @specs/bdc63b-wikipedia-import/plan.md`
